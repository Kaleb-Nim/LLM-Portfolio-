{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import autogen\n",
    "import time\n",
    "from typing import Any, Dict, List, Optional, Union,Tuple,Callable\n",
    "import os \n",
    "from dotenv import load_dotenv\n",
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vaild = load_dotenv()\n",
    "\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = os.environ.get(\"API_KEY\")\n",
    "os.environ[\"AZURE_OPENAI_API_BASE\"] = os.environ.get(\"API_BASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'model': 'gpt-3.5-turbo',\n",
       "  'api_key': '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'},\n",
       " {'model': 'gpt-4',\n",
       "  'api_key': 'e7aab25432084c9ead3eaf0d575e6237',\n",
       "  'api_base': 'https://fintechpoly.openai.azure.com/openai/deployments/fintech-gpt35/chat/completions?api-version=2023-07-01-preview',\n",
       "  'api_type': 'azure',\n",
       "  'api_version': '2023-07-01-preview'},\n",
       " {'model': 'gpt-3.5-turbo',\n",
       "  'api_key': 'e7aab25432084c9ead3eaf0d575e6237',\n",
       "  'api_base': 'https://fintechpoly.openai.azure.com/openai/deployments/fintech-gpt35/chat/completions?api-version=2023-07-01-preview',\n",
       "  'api_type': 'azure',\n",
       "  'api_version': '2023-07-01-preview'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_list = autogen.config_list_from_json(\n",
    "    \"OAI_CONFIG_LIST\",\n",
    "    file_location=\".\",\n",
    "    filter_dict={\n",
    "        \"model\": {\n",
    "            \"gpt-4\",\n",
    "            \"gpt-3.5-turbo\",\n",
    "        }\n",
    "    }\n",
    ")\n",
    "config_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GoogleSearchAgent(autogen.ConversableAgent):\n",
    "    \"\"\"Responsible for using LLM and history context to write gurobipy code\"\"\"\n",
    "\n",
    "    DEFAULT_SYSTEM_MESSAGE = \"\"\"You are a helpful Google Search AI assistant.\n",
    "Solve tasks using Google Search and language skills.\n",
    "In the following cases, suggest python code (in a python coding block) or shell script (in a sh coding block) for the user to execute.\n",
    "    1. When you need to collect info, use the code to output the info you need, for example, browse or search the web, download/read a file, print the content of a webpage or a file, get the current date/time, check the operating system. After sufficient info is printed and the task is ready to be solved based on your language skill, you can solve the task by yourself.\n",
    "Solve the task step by step if you need to. If a plan is not provided, explain your plan first. Be clear which step uses Google Search, and which step uses your language skill.\n",
    "When using code, you must indicate the script type in the code block. The user cannot provide any other feedback or perform any other action beyond executing the code you suggest. The user can't modify your code. So do not suggest incomplete code which requires users to modify. Don't use a code block if it's not intended to be executed by the user.\n",
    "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "When you find an answer, verify the answer carefully. Include verifiable evidence in your response if possible.\n",
    "Reply \"TERMINATE\" in the end when everything is done.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        name: str,\n",
    "        system_message: Optional[str] = DEFAULT_SYSTEM_MESSAGE,\n",
    "        llm_config: Optional[Union[Dict, bool]] = None,\n",
    "        is_termination_msg: Optional[Callable[[Dict], bool]] = None,\n",
    "        max_consecutive_auto_reply: Optional[int] = None,\n",
    "        human_input_mode: Optional[str] = \"NEVER\",\n",
    "        code_execution_config: Optional[Union[Dict, bool]] = False,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            name (str): agent name.\n",
    "            system_message (str): system message for the ChatCompletion inference.\n",
    "                Please override this attribute if you want to reprogram the agent.\n",
    "            llm_config (dict): llm inference configuration.\n",
    "                Please refer to [Completion.create](/docs/reference/oai/completion#create)\n",
    "                for available options.\n",
    "            is_termination_msg (function): a function that takes a message in the form of a dictionary\n",
    "                and returns a boolean value indicating if this received message is a termination message.\n",
    "                The dict can contain the following keys: \"content\", \"role\", \"name\", \"function_call\".\n",
    "            max_consecutive_auto_reply (int): the maximum number of consecutive auto replies.\n",
    "                default to None (no limit provided, class attribute MAX_CONSECUTIVE_AUTO_REPLY will be used as the limit in this case).\n",
    "                The limit only plays a role when human_input_mode is not \"ALWAYS\".\n",
    "            **kwargs (dict): Please refer to other kwargs in\n",
    "                [ConversableAgent](conversable_agent#__init__).\n",
    "        \"\"\"\n",
    "        super().__init__(\n",
    "            name,\n",
    "            system_message,\n",
    "            is_termination_msg,\n",
    "            max_consecutive_auto_reply,\n",
    "            human_input_mode,\n",
    "            code_execution_config=code_execution_config,\n",
    "            llm_config=llm_config,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "googleSearchAgent = GoogleSearchAgent(\n",
    "    name=\"GoogleSearchAgent\",\n",
    "    llm_config={\"config_list\": config_list}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a UserProxyAgent instance named \"user_proxy\"\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "    name=\"user_proxy\",\n",
    "    human_input_mode=\"TERMINATE\",\n",
    "    max_consecutive_auto_reply=10,\n",
    "    is_termination_msg=lambda x: x.get(\"content\", \"\").rstrip().endswith(\"TERMINATE\"),\n",
    "    code_execution_config={\"work_dir\": \"web\"},\n",
    "    llm_config={\"config_list\": config_list},\n",
    "    system_message=\"\"\"Your task is to Validate Business Ideas. Given details about a business idea, Google search for relevant information like Competitors, Reasons why that business idea will fail and suceed and validate the idea.\n",
    "    Reply TERMINATE if the task has been solved at full satisfaction.\n",
    "Otherwise, reply CONTINUE, or the reason why the task is not solved yet.\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33muser_proxy\u001b[0m (to GoogleSearchAgent):\n",
      "\n",
      "\n",
      "One-liner Solution:\n",
      "Automated Last-Mile Delivery Optimization for E-commerce, reducing delivery times and costs through AI-driven routing.\n",
      "\n",
      "Problem Trying to Solve:\n",
      "E-commerce companies struggle with the inefficiencies of last-mile delivery, resulting in delays and high operational \n",
      "costs due to suboptimal routing and unpredictable factors like traffic.\n",
      "\n",
      "Target Audience:\n",
      "E-commerce companies of all sizes seeking to enhance customer satisfaction and streamline their delivery operations.\n",
      "\n",
      "Business Description:\n",
      "Our business, \"RouteSwift,\" leverages artificial intelligence and real-time data analytics to solve the complex problem of \n",
      "last-mile delivery in the e-commerce supply chain. We offer a cloud-based software platform that integrates with \n",
      "e-commerce systems and delivery fleets. RouteSwift optimizes delivery routes in real-time, considering \n",
      "variables like traffic, weather, package size, and delivery windows to ensure parcels are delivered faster and at a reduced cost.\n",
      "By improving efficiency, we help e-commerce companies enhance customer satisfaction, reduce operational costs, \n",
      "and reduce their carbon footprint through more eco-friendly routing.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGoogleSearchAgent\u001b[0m (to user_proxy):\n",
      "\n",
      "To successfully implement an automated last-mile delivery optimization solution for e-commerce, you would need to follow these steps:\n",
      "\n",
      "1. Collect Real-Time Data: Start by collecting real-time data from various sources such as GPS trackers, traffic APIs, weather forecasts, and delivery windows.\n",
      "\n",
      "2. Design AI-Driven Routing Algorithm: Develop an AI-driven routing algorithm that can handle the complexity of last-mile delivery. This algorithm should consider factors such as traffic congestion, delivery windows, package size, and vehicle capacities to optimize the delivery routes.\n",
      "\n",
      "3. Integrate with E-commerce Systems: Build a cloud-based software platform that can seamlessly integrate with e-commerce systems. This integration will allow for the flow of data between the e-commerce platform, delivery fleets, and the optimization algorithm.\n",
      "\n",
      "4. Optimize Delivery Routes: Implement the routing algorithm to optimize the delivery routes in real-time. This optimization should be based on the real-time data collected and consider factors like traffic, weather, and package sizes.\n",
      "\n",
      "5. Communicate with Delivery Fleets: Establish a communication channel with the delivery fleets to provide them with the optimized routes. This can be done through a mobile app or an integrated GPS system.\n",
      "\n",
      "6. Track and Monitor Deliveries: Implement a system to track and monitor the deliveries in real-time. This will help identify any issues or delays and allow for prompt actions to be taken.\n",
      "\n",
      "7. Analyze Performance and Optimize: Continuously analyze the performance of the delivery optimization solution and make necessary improvements. This can involve tweaking the routing algorithm or integrating additional data sources.\n",
      "\n",
      "By following these steps, you can create an automated last-mile delivery optimization solution for e-commerce, reducing delivery times and costs through AI-driven routing.\n",
      "\n",
      "TERMINATE\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# the assistant receives a message from the user, which contains the task description\n",
    "user_proxy.initiate_chat(\n",
    "    googleSearchAgent,\n",
    "    message=\"\"\"\n",
    "One-liner Solution:\n",
    "Automated Last-Mile Delivery Optimization for E-commerce, reducing delivery times and costs through AI-driven routing.\n",
    "\n",
    "Problem Trying to Solve:\n",
    "E-commerce companies struggle with the inefficiencies of last-mile delivery, resulting in delays and high operational \n",
    "costs due to suboptimal routing and unpredictable factors like traffic.\n",
    "\n",
    "Target Audience:\n",
    "E-commerce companies of all sizes seeking to enhance customer satisfaction and streamline their delivery operations.\n",
    "\n",
    "Business Description:\n",
    "Our business, \"RouteSwift,\" leverages artificial intelligence and real-time data analytics to solve the complex problem of \n",
    "last-mile delivery in the e-commerce supply chain. We offer a cloud-based software platform that integrates with \n",
    "e-commerce systems and delivery fleets. RouteSwift optimizes delivery routes in real-time, considering \n",
    "variables like traffic, weather, package size, and delivery windows to ensure parcels are delivered faster and at a reduced cost.\n",
    "By improving efficiency, we help e-commerce companies enhance customer satisfaction, reduce operational costs, \n",
    "and reduce their carbon footprint through more eco-friendly routing.\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using groupchat manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt4_config = {\n",
    "    \"seed\": 42,  # change the seed for different trials\n",
    "    \"temperature\": 0,\n",
    "    \"config_list\": config_list,\n",
    "    \"request_timeout\": 120,\n",
    "}\n",
    "user_proxy = autogen.UserProxyAgent(\n",
    "   name=\"Admin\",\n",
    "   system_message=\"A human admin. Interact with the planner to discuss the plan. Plan execution needs to be approved by this admin.\",\n",
    "   code_execution_config=False,\n",
    ")\n",
    "GoogleSearchAgent = autogen.AssistantAgent(\n",
    "    name=\"Google Search Query\",\n",
    "    llm_config=gpt4_config,\n",
    "    system_message='''Google Search Query for vaildating business ideas. You follow an approved plan. You write python/shell code to solve tasks, including google searching. Wrap the code in a code block that specifies the script type. The user can't modify your code. So do not suggest incomplete code which requires others to modify. Don't use a code block if it's not intended to be executed by the executor.\n",
    "Don't include multiple code blocks in one response. Do not ask others to copy and paste the result. Check the execution result returned by the executor.\n",
    "If the result indicates there is an error, fix the error and output the code again. Suggest the full code instead of partial code or code changes. If the error can't be fixed or if the task is not solved even after the code is executed successfully, analyze the problem, revisit your assumption, collect additional info you need, and think of a different approach to try.\n",
    "''',\n",
    ")\n",
    "GoogleSearchAnalyzer = autogen.AssistantAgent(\n",
    "    name=\"Google Search Analyzer\",\n",
    "    llm_config=gpt4_config,\n",
    "    system_message=\"\"\"Google Search Analyzer, you will read and understand the relevant google search results. You till analyze and complie the relevant infomation based on the End goal questions and original business idea\"\"\"\n",
    ")\n",
    "planner = autogen.AssistantAgent(\n",
    "    name=\"Planner\",\n",
    "    system_message='''Planner. Suggest a plan. Revise the plan based on feedback from admin and critic, until admin approval.\n",
    "The plan may involve an Google Search Query who can write code and a Google Search Analyzer who doesn't write code.\n",
    "Explain the plan first. Be clear which step is performed by an Google Search Query, and which step is performed by a Google Search Analyzer.\n",
    "''',\n",
    "    llm_config=gpt4_config,\n",
    ")\n",
    "executor = autogen.UserProxyAgent(\n",
    "    name=\"Executor\",\n",
    "    system_message=\"Executor. Execute the code written by the engineer and report the result.\",\n",
    "    human_input_mode=\"NEVER\",\n",
    "    code_execution_config={\"last_n_messages\": 3, \"work_dir\": \"paper\"},\n",
    ")\n",
    "critic = autogen.AssistantAgent(\n",
    "    name=\"Critic\",\n",
    "    system_message=\"Critic. Double check plan, claims, code from other agents and provide feedback. Check whether the plan includes adding verifiable info such as source URL.\",\n",
    "    llm_config=gpt4_config,\n",
    ")\n",
    "groupchat = autogen.GroupChat(agents=[user_proxy, GoogleSearchAgent, GoogleSearchAnalyzer, planner, executor, critic], messages=[], max_round=50)\n",
    "\n",
    "manager = autogen.GroupChatManager(\n",
    "    groupchat=groupchat, \n",
    "    llm_config=gpt4_config,\n",
    "    system_message=\"Group chat manager, Main goal is to perform full market validation of the following idea. Accomplish the following Tasks 1.competition survey and analysis, and where to sell products , 2.how much to sell for and how to sell, 3.best advertisement of competitions and how u can leverage same technique to market your product. All in table format at the end\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mAdmin\u001b[0m (to chat_manager):\n",
      "\n",
      "\n",
      "One-liner Solution:\n",
      "Automated Last-Mile Delivery Optimization for E-commerce, reducing delivery times and costs through AI-driven routing.\n",
      "\n",
      "Problem Trying to Solve:\n",
      "E-commerce companies struggle with the inefficiencies of last-mile delivery, resulting in delays and high operational \n",
      "costs due to suboptimal routing and unpredictable factors like traffic.\n",
      "\n",
      "Target Audience:\n",
      "E-commerce companies of all sizes seeking to enhance customer satisfaction and streamline their delivery operations.\n",
      "\n",
      "Business Description:\n",
      "Our business, \"RouteSwift,\" leverages artificial intelligence and real-time data analytics to solve the complex problem of \n",
      "last-mile delivery in the e-commerce supply chain. We offer a cloud-based software platform that integrates with \n",
      "e-commerce systems and delivery fleets. RouteSwift optimizes delivery routes in real-time, considering \n",
      "variables like traffic, weather, package size, and delivery windows to ensure parcels are delivered faster and at a reduced cost.\n",
      "By improving efficiency, we help e-commerce companies enhance customer satisfaction, reduce operational costs, \n",
      "and reduce their carbon footprint through more eco-friendly routing.\n",
      "\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mPlanner\u001b[0m (to chat_manager):\n",
      "\n",
      "Plan:\n",
      "\n",
      "1. Research and Development (Google Search Query):\n",
      "   - Conduct a comprehensive search to understand the current challenges and trends in last-mile delivery optimization for e-commerce.\n",
      "   - Identify existing AI-driven routing solutions and their features.\n",
      "   - Explore real-time data analytics techniques and algorithms used in optimizing delivery routes.\n",
      "   - Investigate the integration possibilities with e-commerce systems and delivery fleets.\n",
      "\n",
      "2. Market Analysis (Google Search Analyzer):\n",
      "   - Conduct market research to identify the target audience and their pain points in last-mile delivery.\n",
      "   - Analyze the competitive landscape to understand the existing solutions and their limitations.\n",
      "   - Identify potential market opportunities and assess the demand for an AI-driven last-mile delivery optimization solution.\n",
      "\n",
      "3. Solution Development (Google Search Query):\n",
      "   - Research and identify the technologies and tools required to develop an AI-driven routing solution.\n",
      "   - Explore cloud-based software platforms and their integration capabilities with e-commerce systems and delivery fleets.\n",
      "   - Investigate real-time data analytics techniques and algorithms suitable for optimizing delivery routes.\n",
      "   - Develop a prototype of the RouteSwift software platform that can optimize delivery routes based on various variables.\n",
      "\n",
      "4. Testing and Validation (Google Search Analyzer):\n",
      "   - Conduct extensive testing of the RouteSwift software platform to ensure its accuracy and efficiency in optimizing delivery routes.\n",
      "   - Validate the solution by running simulations and comparing the results with existing routing methods.\n",
      "   - Gather feedback from potential users and incorporate necessary improvements based on their suggestions.\n",
      "\n",
      "5. Business Model and Marketing Strategy (Google Search Analyzer):\n",
      "   - Research and analyze different business models for offering the RouteSwift solution to e-commerce companies.\n",
      "   - Identify pricing strategies and revenue streams that align with the value provided by the optimized last-mile delivery.\n",
      "   - Develop a marketing strategy to reach out to the target audience and create awareness about the benefits of RouteSwift.\n",
      "   - Analyze the potential partnerships and collaborations with e-commerce platforms, logistics providers, and technology companies.\n",
      "\n",
      "6. Launch and Deployment (Google Search Analyzer):\n",
      "   - Plan the launch of RouteSwift, including the release timeline and marketing campaigns.\n",
      "   - Collaborate with e-commerce companies to integrate the RouteSwift software platform into their existing systems.\n",
      "   - Provide training and support to the users to ensure a smooth transition to the optimized last-mile delivery process.\n",
      "   - Continuously monitor and analyze the performance of RouteSwift, gather user feedback, and make necessary improvements.\n",
      "\n",
      "7. Continuous Improvement and Expansion (Google Search Query):\n",
      "   - Stay updated with the latest advancements in AI-driven routing and real-time data analytics.\n",
      "   - Research and implement new features and enhancements to further optimize the last-mile delivery process.\n",
      "   - Explore opportunities to expand the RouteSwift solution to other industries or geographical regions.\n",
      "   - Monitor the market trends and competition to ensure RouteSwift remains a leading solution in the last-mile delivery optimization space.\n",
      "\n",
      "Note: The Google Search Query will be responsible for conducting research, gathering information, and finding relevant resources and tools. The Google Search Analyzer will analyze the gathered information, perform market analysis, validate the solution, and develop business strategies.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mCritic\u001b[0m (to chat_manager):\n",
      "\n",
      "Feedback:\n",
      "\n",
      "Overall, the plan seems comprehensive and covers the necessary steps for developing and launching the RouteSwift solution. However, there are a few areas that could be improved:\n",
      "\n",
      "1. Research and Development:\n",
      "   - It would be beneficial to include specific sources or URLs for conducting the research. This will help ensure that the information gathered is reliable and verifiable.\n",
      "\n",
      "2. Market Analysis:\n",
      "   - In addition to using a Google Search Analyzer, consider utilizing other market research methods such as surveys or interviews with potential customers. This will provide more in-depth insights into the target audience's pain points and preferences.\n",
      "\n",
      "3. Solution Development:\n",
      "   - Specify the programming languages, frameworks, or tools that will be used for developing the AI-driven routing solution. This will provide more clarity on the technical aspects of the development process.\n",
      "\n",
      "4. Testing and Validation:\n",
      "   - Consider including a plan for conducting real-world tests with a small group of users or pilot customers. This will help validate the solution's effectiveness in a practical setting.\n",
      "\n",
      "5. Business Model and Marketing Strategy:\n",
      "   - Provide more details on the specific pricing strategies and revenue streams that will be used. This will help demonstrate the viability and profitability of the business model.\n",
      "\n",
      "6. Continuous Improvement and Expansion:\n",
      "   - Include a plan for gathering and analyzing customer feedback on an ongoing basis. This will ensure that the solution remains aligned with customer needs and expectations.\n",
      "\n",
      "By addressing these areas, the plan will become more robust and provide a clearer roadmap for developing and launching the RouteSwift solution.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mGoogle Search Analyzer\u001b[0m (to chat_manager):\n",
      "\n",
      "Thank you for your feedback. I appreciate your suggestions for improvement. Here are the revised sections based on your feedback:\n",
      "\n",
      "1. Research and Development:\n",
      "   - Conduct a comprehensive search using reliable sources such as industry reports, academic journals, and reputable websites to understand the current challenges and trends in last-mile delivery optimization for e-commerce.\n",
      "\n",
      "2. Market Analysis:\n",
      "   - Utilize a combination of market research methods, including surveys and interviews with potential customers, to gain in-depth insights into the target audience's pain points and preferences.\n",
      "\n",
      "3. Solution Development:\n",
      "   - Specify the programming languages, frameworks, or tools that will be used for developing the AI-driven routing solution, such as Python, TensorFlow, and Google Cloud Platform.\n",
      "\n",
      "4. Testing and Validation:\n",
      "   - Include a plan for conducting real-world tests with a small group of users or pilot customers to validate the solution's effectiveness in a practical setting. This can involve collecting feedback and analyzing key performance metrics.\n",
      "\n",
      "5. Business Model and Marketing Strategy:\n",
      "   - Provide more details on the specific pricing strategies and revenue streams that will be used, such as subscription-based pricing or transaction-based fees. This will demonstrate the viability and profitability of the business model.\n",
      "\n",
      "6. Continuous Improvement and Expansion:\n",
      "   - Include a plan for gathering and analyzing customer feedback on an ongoing basis, such as through regular surveys or feedback loops. This will ensure that the solution remains aligned with customer needs and expectations.\n",
      "\n",
      "By incorporating these revisions, the plan will become more comprehensive and address the areas for improvement you highlighted. Thank you again for your valuable feedback.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "InvalidRequestError",
     "evalue": "Resource not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidRequestError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\autogen3.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m user_proxy\u001b[39m.\u001b[39;49minitiate_chat(\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     manager,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     message\u001b[39m=\u001b[39;49m\u001b[39m\"\"\"\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mOne-liner Solution:\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mAutomated Last-Mile Delivery Optimization for E-commerce, reducing delivery times and costs through AI-driven routing.\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39mProblem Trying to Solve:\u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mE-commerce companies struggle with the inefficiencies of last-mile delivery, resulting in delays and high operational \u001b[39;49m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39mcosts due to suboptimal routing and unpredictable factors like traffic.\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mTarget Audience:\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mE-commerce companies of all sizes seeking to enhance customer satisfaction and streamline their delivery operations.\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mBusiness Description:\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mOur business, \u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRouteSwift,\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m leverages artificial intelligence and real-time data analytics to solve the complex problem of \u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39mlast-mile delivery in the e-commerce supply chain. We offer a cloud-based software platform that integrates with \u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39me-commerce systems and delivery fleets. RouteSwift optimizes delivery routes in real-time, considering \u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mvariables like traffic, weather, package size, and delivery windows to ensure parcels are delivered faster and at a reduced cost.\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mBy improving efficiency, we help e-commerce companies enhance customer satisfaction, reduce operational costs, \u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mand reduce their carbon footprint through more eco-friendly routing.\u001b[39;49m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m\"\"\"\u001b[39;49m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/stu-kalebnim/Documents/GitHub/LLM-Portfolio-/autogen3.ipynb#X13sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:531\u001b[0m, in \u001b[0;36mConversableAgent.initiate_chat\u001b[1;34m(self, recipient, clear_history, silent, **context)\u001b[0m\n\u001b[0;32m    517\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Initiate a chat with the recipient agent.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[39mReset the consecutive auto reply counter.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39m        \"message\" needs to be provided if the `generate_init_message` method is not overridden.\u001b[39;00m\n\u001b[0;32m    529\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    530\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_chat(recipient, clear_history)\n\u001b[1;32m--> 531\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_init_message(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcontext), recipient, silent\u001b[39m=\u001b[39;49msilent)\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:334\u001b[0m, in \u001b[0;36mConversableAgent.send\u001b[1;34m(self, message, recipient, request_reply, silent)\u001b[0m\n\u001b[0;32m    332\u001b[0m valid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_append_oai_message(message, \u001b[39m\"\u001b[39m\u001b[39massistant\u001b[39m\u001b[39m\"\u001b[39m, recipient)\n\u001b[0;32m    333\u001b[0m \u001b[39mif\u001b[39;00m valid:\n\u001b[1;32m--> 334\u001b[0m     recipient\u001b[39m.\u001b[39;49mreceive(message, \u001b[39mself\u001b[39;49m, request_reply, silent)\n\u001b[0;32m    335\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    336\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    337\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mMessage can\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be converted into a valid ChatCompletion message. Either content or function_call must be provided.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    338\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:462\u001b[0m, in \u001b[0;36mConversableAgent.receive\u001b[1;34m(self, message, sender, request_reply, silent)\u001b[0m\n\u001b[0;32m    460\u001b[0m \u001b[39mif\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m request_reply \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreply_at_receive[sender] \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[0;32m    461\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m--> 462\u001b[0m reply \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgenerate_reply(messages\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mchat_messages[sender], sender\u001b[39m=\u001b[39;49msender)\n\u001b[0;32m    463\u001b[0m \u001b[39mif\u001b[39;00m reply \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(reply, sender, silent\u001b[39m=\u001b[39msilent)\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:781\u001b[0m, in \u001b[0;36mConversableAgent.generate_reply\u001b[1;34m(self, messages, sender, exclude)\u001b[0m\n\u001b[0;32m    779\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    780\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_match_trigger(reply_func_tuple[\u001b[39m\"\u001b[39m\u001b[39mtrigger\u001b[39m\u001b[39m\"\u001b[39m], sender):\n\u001b[1;32m--> 781\u001b[0m     final, reply \u001b[39m=\u001b[39m reply_func(\u001b[39mself\u001b[39;49m, messages\u001b[39m=\u001b[39;49mmessages, sender\u001b[39m=\u001b[39;49msender, config\u001b[39m=\u001b[39;49mreply_func_tuple[\u001b[39m\"\u001b[39;49m\u001b[39mconfig\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[0;32m    782\u001b[0m     \u001b[39mif\u001b[39;00m final:\n\u001b[0;32m    783\u001b[0m         \u001b[39mreturn\u001b[39;00m reply\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\autogen\\agentchat\\groupchat.py:127\u001b[0m, in \u001b[0;36mGroupChatManager.run_chat\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m    125\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m     \u001b[39m# select the next speaker\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m     speaker \u001b[39m=\u001b[39m groupchat\u001b[39m.\u001b[39;49mselect_speaker(speaker, \u001b[39mself\u001b[39;49m)\n\u001b[0;32m    128\u001b[0m     \u001b[39m# let the speaker speak\u001b[39;00m\n\u001b[0;32m    129\u001b[0m     reply \u001b[39m=\u001b[39m speaker\u001b[39m.\u001b[39mgenerate_reply(sender\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\autogen\\agentchat\\groupchat.py:56\u001b[0m, in \u001b[0;36mGroupChat.select_speaker\u001b[1;34m(self, last_speaker, selector)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[39mif\u001b[39;00m n_agents \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[0;32m     52\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[0;32m     53\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mGroupChat is underpopulated with \u001b[39m\u001b[39m{\u001b[39;00mn_agents\u001b[39m}\u001b[39;00m\u001b[39m agents. Direct communication would be more efficient.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     54\u001b[0m     )\n\u001b[1;32m---> 56\u001b[0m final, name \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mgenerate_oai_reply(\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessages\n\u001b[0;32m     58\u001b[0m     \u001b[39m+\u001b[39;49m [\n\u001b[0;32m     59\u001b[0m         {\n\u001b[0;32m     60\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mrole\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39m\"\u001b[39;49m\u001b[39msystem\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     61\u001b[0m             \u001b[39m\"\u001b[39;49m\u001b[39mcontent\u001b[39;49m\u001b[39m\"\u001b[39;49m: \u001b[39mf\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mRead the above conversation. Then select the next role from \u001b[39;49m\u001b[39m{\u001b[39;49;00m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49magent_names\u001b[39m}\u001b[39;49;00m\u001b[39m to play. Only return the role.\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     62\u001b[0m         }\n\u001b[0;32m     63\u001b[0m     ]\n\u001b[0;32m     64\u001b[0m )\n\u001b[0;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m final:\n\u001b[0;32m     66\u001b[0m     \u001b[39m# i = self._random.randint(0, len(self._agent_names) - 1)  # randomly pick an id\u001b[39;00m\n\u001b[0;32m     67\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnext_agent(last_speaker)\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\autogen\\agentchat\\conversable_agent.py:606\u001b[0m, in \u001b[0;36mConversableAgent.generate_oai_reply\u001b[1;34m(self, messages, sender, config)\u001b[0m\n\u001b[0;32m    603\u001b[0m     messages \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_messages[sender]\n\u001b[0;32m    605\u001b[0m \u001b[39m# TODO: #1143 handle token limit exceeded error\u001b[39;00m\n\u001b[1;32m--> 606\u001b[0m response \u001b[39m=\u001b[39m oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mcreate(\n\u001b[0;32m    607\u001b[0m     context\u001b[39m=\u001b[39mmessages[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mcontext\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m), messages\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_oai_system_message \u001b[39m+\u001b[39m messages, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mllm_config\n\u001b[0;32m    608\u001b[0m )\n\u001b[0;32m    609\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m, oai\u001b[39m.\u001b[39mChatCompletion\u001b[39m.\u001b[39mextract_text_or_function_call(response)[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\autogen\\oai\\completion.py:799\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[0;32m    797\u001b[0m     base_config[\u001b[39m\"\u001b[39m\u001b[39mmax_retry_period\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m    798\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 799\u001b[0m     response \u001b[39m=\u001b[39m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcreate(\n\u001b[0;32m    800\u001b[0m         context,\n\u001b[0;32m    801\u001b[0m         use_cache,\n\u001b[0;32m    802\u001b[0m         raise_on_ratelimit_or_timeout\u001b[39m=\u001b[39mi \u001b[39m<\u001b[39m last \u001b[39mor\u001b[39;00m raise_on_ratelimit_or_timeout,\n\u001b[0;32m    803\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mbase_config,\n\u001b[0;32m    804\u001b[0m     )\n\u001b[0;32m    805\u001b[0m     \u001b[39mif\u001b[39;00m response \u001b[39m==\u001b[39m \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m:\n\u001b[0;32m    806\u001b[0m         \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\autogen\\oai\\completion.py:830\u001b[0m, in \u001b[0;36mCompletion.create\u001b[1;34m(cls, context, use_cache, config_list, filter_func, raise_on_ratelimit_or_timeout, allow_format_str_template, **config)\u001b[0m\n\u001b[0;32m    828\u001b[0m \u001b[39mwith\u001b[39;00m diskcache\u001b[39m.\u001b[39mCache(\u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mcache_path) \u001b[39mas\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39m_cache:\n\u001b[0;32m    829\u001b[0m     \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39mset_cache(seed)\n\u001b[1;32m--> 830\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m\u001b[39m.\u001b[39;49m_get_response(params, raise_on_ratelimit_or_timeout\u001b[39m=\u001b[39;49mraise_on_ratelimit_or_timeout)\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\autogen\\oai\\completion.py:218\u001b[0m, in \u001b[0;36mCompletion._get_response\u001b[1;34m(cls, config, raise_on_ratelimit_or_timeout, use_cache)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    217\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mrequest_timeout\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m config:\n\u001b[1;32m--> 218\u001b[0m         response \u001b[39m=\u001b[39m openai_completion\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n\u001b[0;32m    219\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    220\u001b[0m         response \u001b[39m=\u001b[39m openai_completion\u001b[39m.\u001b[39mcreate(request_timeout\u001b[39m=\u001b[39mrequest_timeout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig)\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:155\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    130\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    131\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    138\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    139\u001b[0m ):\n\u001b[0;32m    140\u001b[0m     (\n\u001b[0;32m    141\u001b[0m         deployment_id,\n\u001b[0;32m    142\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    152\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    153\u001b[0m     )\n\u001b[1;32m--> 155\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    156\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    157\u001b[0m         url,\n\u001b[0;32m    158\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    159\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    160\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    161\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    162\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    165\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    166\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    167\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\openai\\api_requestor.py:299\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    279\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    280\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    287\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    288\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[0;32m    289\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrequest_raw(\n\u001b[0;32m    290\u001b[0m         method\u001b[39m.\u001b[39mlower(),\n\u001b[0;32m    291\u001b[0m         url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    297\u001b[0m         request_timeout\u001b[39m=\u001b[39mrequest_timeout,\n\u001b[0;32m    298\u001b[0m     )\n\u001b[1;32m--> 299\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response(result, stream)\n\u001b[0;32m    300\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\openai\\api_requestor.py:710\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response\u001b[1;34m(self, result, stream)\u001b[0m\n\u001b[0;32m    702\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[0;32m    703\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response_line(\n\u001b[0;32m    704\u001b[0m             line, result\u001b[39m.\u001b[39mstatus_code, result\u001b[39m.\u001b[39mheaders, stream\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    705\u001b[0m         )\n\u001b[0;32m    706\u001b[0m         \u001b[39mfor\u001b[39;00m line \u001b[39min\u001b[39;00m parse_stream(result\u001b[39m.\u001b[39miter_lines())\n\u001b[0;32m    707\u001b[0m     ), \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    709\u001b[0m     \u001b[39mreturn\u001b[39;00m (\n\u001b[1;32m--> 710\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_interpret_response_line(\n\u001b[0;32m    711\u001b[0m             result\u001b[39m.\u001b[39;49mcontent\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m    712\u001b[0m             result\u001b[39m.\u001b[39;49mstatus_code,\n\u001b[0;32m    713\u001b[0m             result\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    714\u001b[0m             stream\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    715\u001b[0m         ),\n\u001b[0;32m    716\u001b[0m         \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    717\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\stu-kalebnim\\Documents\\GitHub\\LLM-Portfolio-\\venv\\lib\\site-packages\\openai\\api_requestor.py:775\u001b[0m, in \u001b[0;36mAPIRequestor._interpret_response_line\u001b[1;34m(self, rbody, rcode, rheaders, stream)\u001b[0m\n\u001b[0;32m    773\u001b[0m stream_error \u001b[39m=\u001b[39m stream \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39merror\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m resp\u001b[39m.\u001b[39mdata\n\u001b[0;32m    774\u001b[0m \u001b[39mif\u001b[39;00m stream_error \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m200\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m rcode \u001b[39m<\u001b[39m \u001b[39m300\u001b[39m:\n\u001b[1;32m--> 775\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_error_response(\n\u001b[0;32m    776\u001b[0m         rbody, rcode, resp\u001b[39m.\u001b[39mdata, rheaders, stream_error\u001b[39m=\u001b[39mstream_error\n\u001b[0;32m    777\u001b[0m     )\n\u001b[0;32m    778\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "\u001b[1;31mInvalidRequestError\u001b[0m: Resource not found"
     ]
    }
   ],
   "source": [
    "user_proxy.initiate_chat(\n",
    "    manager,\n",
    "    message=\"\"\"\n",
    "One-liner Solution:\n",
    "Automated Last-Mile Delivery Optimization for E-commerce, reducing delivery times and costs through AI-driven routing.\n",
    "\n",
    "Problem Trying to Solve:\n",
    "E-commerce companies struggle with the inefficiencies of last-mile delivery, resulting in delays and high operational \n",
    "costs due to suboptimal routing and unpredictable factors like traffic.\n",
    "\n",
    "Target Audience:\n",
    "E-commerce companies of all sizes seeking to enhance customer satisfaction and streamline their delivery operations.\n",
    "\n",
    "Business Description:\n",
    "Our business, \"RouteSwift,\" leverages artificial intelligence and real-time data analytics to solve the complex problem of \n",
    "last-mile delivery in the e-commerce supply chain. We offer a cloud-based software platform that integrates with \n",
    "e-commerce systems and delivery fleets. RouteSwift optimizes delivery routes in real-time, considering \n",
    "variables like traffic, weather, package size, and delivery windows to ensure parcels are delivered faster and at a reduced cost.\n",
    "By improving efficiency, we help e-commerce companies enhance customer satisfaction, reduce operational costs, \n",
    "and reduce their carbon footprint through more eco-friendly routing.\n",
    "\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<autogen.agentchat.assistant_agent.AssistantAgent at 0x23636225750>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupchat.agent_by_name(name=\"Google Search Analyzer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
